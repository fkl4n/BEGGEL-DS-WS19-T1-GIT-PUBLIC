---
title: "CSVFileImport"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
# plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

# Load Libraries
```{r,  warning=FALSE,include= TRUE,echo=TRUE,results='hide', message=FALSE}
#install.packages("dplyr")
#install.packages("stringr")
#install.packages("graphics")


# load installed libraries 
library(dplyr)
library(stringr)
library(graphics)
library(ggplot2)

```

```{r}
setwd("K:/Data Science/Projekt/BEGGEL-DS-WS19-T1-GIT/")
```

```{r}
for (path in c("../Workspace/PostgreSQL.csv", "../Workspace/MySql.csv", "../Workspace/MongoDB.csv")){

  print(val)
  ### Load Data - Start ###

  db_urls = read.csv('../data/database_list.csv', header=TRUE, encoding = "UTF-8", na.strings = "null")
  db_infos = read.csv('../DBEngines/DBRanking.csv', header=TRUE, encoding = "UTF-8", na.strings = "null") 

  # Git-History for DBs (default-branch)
  db_git_history = read.csv(path, header=TRUE, encoding = "UTF-8", na.strings = "null", sep = ";")
  
  ### Load Data - Ende ###

  ### Create Base-Dataframe - Start ###

  # get the names of the preselected DBs
  names = as.vector(db_urls$URLName)  

  # select preselected entries 
  selected_rows = db_infos[tolower(db_infos$URLName) %in% tolower(names), ]

  # remove "Rank"-column
  tmp_df = db_urls[,!(names(db_urls) %in% c("Rank"))]

  # create a dataframe with information about the preselected DBs
  base_df =  right_join(selected_rows, tmp_df, by = "URLName")
  
  # Create Base-Dataframe - Ende
  
  # Examine Dataframe
  # head(base_df)

  # str(base_df)

  # summary(base_df)

  ### Cleaning and Prepping Data - Start ### 
  
  # Remove unneccesary columns
  drop_list = c("Name", "Ausschließlich.ein.Cloud.Service", "DBaaS.Angebote", "Anmerkung")
  result_meta_df = base_df[ , !(names(base_df) %in% drop_list)]
  
  # check the values class
  # lapply(result_meta_df$Rang, class)
  
  # The following variables were imported as factors, but they should be numerical 
  columns_to_numeric = c("Punkte", "Rang", "Suchmaschinen","Erscheinungsjahr", 
                         "Graph.DBMS", "Document.Stores", "Key.Value.Stores", "Relational.DBMS",
                         "Time.Series.DBMS", "Multivalue.DBMS", "Object.oriented.DBMS", "RDF.Stores", 
                         "Wide.Column.Stores", "Navigational.DBMS", "Event.Stores", "Native.XML.DBMS",
                         "Content.Stores")
  result_meta_df[columns_to_numeric] = lapply(result_meta_df[columns_to_numeric], as.numeric)
  
  # The following variables were imported as factors, but they should be characters
  columons_to_chr = c("Kurzbeschreibung", "Website", "Technische.Dokumentation", "Entwickler",
                      "Aktuelle.Version", "Server.Betriebssysteme", "Git_URL")
  result_meta_df[columons_to_chr] = lapply(result_meta_df[columons_to_chr], as.character)
  
  # Convert timestamp from feactor to POSIXct format
  db_git_history["timestamp"] = lapply(db_git_history["timestamp"], function(x) as.POSIXct(x, format='%Y-%m-%dT%H:%M:%S'))
  
  
  # Define Function in order to extract the FileEnding
  extractFileExtension = function(x){
    lapply(str_split(x, "[.]"), tail, 1)
  }
  
  
  # Add new column for the FileExtenstion to the data frame
  db_git_history["fileExtension"] = lapply(db_git_history["file"], function(x) extractFileExtension(x))
  
  # Convert all indistinguishable value to "unknown"
  db_git_history["fileExtension"] = lapply(db_git_history["fileExtension"], function(x) ifelse(grepl("[/]", x), "unknown", x))
  
  # Flatten the resulting List to a vector
  db_git_history["fileExtension"] = unlist(db_git_history$fileExtension, use.names=FALSE)
  
  # Convert the FileExtensions to factors
  db_git_history$fileExtension = as.factor(db_git_history$fileExtension)
  
  # provisionally renamed: "result" marks the data frames to plot with
  result_git_df = db_git_history
    
  ### Cleaning and Prepping Data - Ende ### 
  
  ### Plots zur allgemeinen ÜbersichsÜbersicht - Start ###

  extract_specific_data <- result_git_df %>% 
  group_by(name, commit, authorName, authorEmail, timestamp) %>% 
  summarise(change = sum(change)) %>%
  arrange((timestamp), .by_group = FALSE)

  change_cum = cumsum(extract_specific_data$change)
  extract_specific_data = cbind(extract_specific_data,change_cum = change_cum)
  
  #Anzahl der Änderungen über die Zeit
  print(ggplot(extract_specific_data, aes(x=timestamp, y=change)) + geom_point())
  
  #Anzahl der kumulierten Änderungen über die Zeit
  print(ggplot(extract_specific_data, aes(x=timestamp, y=change_cum)) + geom_line())
  
  extract_specific_data2 <- result_git_df %>% 
    group_by(commit, file, timestamp) %>% 
    summarise(change = sum(change)) %>%
    arrange((timestamp), .by_group = FALSE)
  
  files <- result_git_df %>% 
    distinct(file)
  
  print(ggplot(data = subset(extract_specific_data2, file %in% files[0:5,])) + geom_point(aes(x=timestamp, y=change, colour=file)))
    
  ### Plots zur allgemeinen ÜbersichsÜbersicht - Ende ###

  ### Plots zur Lösung derAufgabe - Start ###

  #Hinzufügen einer Spalte die die Änderungen pro File aufzummiert.
  df = result_git_df %>% 
    group_by(file) %>%
    arrange(file, timestamp) %>%
    mutate(fileSize = cumsum(change))
  
  print(df)
  
  #Dataframe der die Korrelation zwischen Commitgröße und Filegröße enthält.
  correlation_per_file = df %>% 
    group_by(file) %>%
    summarize(correlation=cor(change,fileSize))
  
  print(correlation_per_file)
  
  #Plot Korrelation zwischen Commitgröße und Filegröße.
  print(ggplot(correlation_per_file, aes(x=file, y=correlation)) + geom_point())
  
  correlation_per_file$file <- reorder(correlation_per_file$file, correlation_per_file$correlation)
  
  #Plot Korrelation zwischen Commitgröße und Filegröße, sortiert nach der Größe des Korrelationskoeffizients.
  print(ggplot(correlation_per_file, aes(x=file, y=correlation)) + geom_point())
  
  #Durchschitt aller Korrelationskoeffizienten.
  correlation_mean = mean(correlation_per_file$correlation, na.rm = TRUE)  
  print(correlation_mean)
    
  ### Plots zur Lösung derAufgabe - Ende ###


}

```

